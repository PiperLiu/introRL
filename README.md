# Notes for RL Video Lectures
ç”¨ä¸­æ–‡è®°å½•ä¸€äº›å¼ºåŒ–å­¦ä¹ ç¬”è®°ï¼Œæ¯”å¦‚å‘¨åšç£Šè€å¸ˆçš„è§†é¢‘è¯¾ç¨‹ã€RLChinaçš„è§†é¢‘è¯¾ç¨‹ã€è®ºæ–‡é˜…è¯»ç¬”è®°ã€‚é€‚äºæœ‰ä¸€å®šåŸºç¡€çš„å°ä¼™ä¼´å­¦ä¹ çš„èµ„æ–™ã€‚

### æˆ‘çš„ç¬”è®°åˆ†å¸ƒ
- ğŸ¥Š å…¥é—¨å­¦ä¹  / è¯»ä¹¦ç¬”è®° [GitHubé“¾æ¥ï¼šPiperLiu/Reinforcement-Learning-practice-zh](https://github.com/PiperLiu/Reinforcement-Learning-practice-zh)
- ğŸ’» é˜…è¯»è®ºæ–‡ / è§†é¢‘è¯¾ç¨‹çš„ç¬”è®° [GitHubé“¾æ¥ï¼šPiperLiu/introRL](https://github.com/PiperLiu/introRL)
- âœ¨ å¤§å°ç®—æ³• / ç»ƒæ‰‹æ“åœº [GitHubé“¾æ¥ï¼šPiperLiu/Approachable-Reinforcement-Learning](https://github.com/PiperLiu/Approachable-Reinforcement-Learning)

## Catalog
- [å‘¨åšç£Šè€å¸ˆçš„è§†é¢‘è¯¾ç¨‹](#Bolei_Zhou)
- [RLChinaçš„è§†é¢‘è¯¾ç¨‹](#RLChina)
- [è®ºæ–‡é˜…è¯»ç¬”è®°](#./papers/README.md)

## Overview for Each Course
### Bolei_Zhou
å‘¨åšç£Šè€å¸ˆçš„è§†é¢‘è¯¾ç¨‹ï¼Œæˆ‘å°†å…¶å®šä½ä¸ºï¼š
- ä¸­è§„ä¸­çŸ©ã€ç³»ç»Ÿçš„`æ·±åº¦å¼ºåŒ–å­¦ä¹ `å…¥é—¨è¯¾ç¨‹ï¼›
- ä¸å¼ºåŒ–å­¦ä¹ åœ£ç»ä¹¦ Introduction åŒï¼Œå…¶ä¹Ÿæ˜¯ä»é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸ `value-based(DQN)` å…¥æ‰‹ï¼Œä½†å¼¥è¡¥äº†åœ£ç»ä¹¦ä¸­`æ·±åº¦å¼ºåŒ–å­¦ä¹ `ä¸`è¿‘å¹´æ¥æˆæœ`çš„ç¼ºå¤±ï¼›
- å…³äº SOTA çš„ä¸¤æ¡å‘å±•çº¿ï¼Œè§ä¸‹è¡¨ï¼›
- åœ¨ SOTA çš„å†…å®¹åï¼Œè®²è§£äº†`åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ `ã€`æ¨¡ä»¿å­¦ä¹ `å’Œ`å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ ï¼ˆåˆ†å¸ƒå¼ç³»ç»Ÿï¼‰`ï¼Œç®—æ˜¯ç§‘æ™®äº†ï¼›
- æ²¡æœ‰å…³äº MARL å¤šæ™ºèƒ½ä½“çš„å†…å®¹ã€‚

æ­¤å¤–ï¼Œ`å‘¨è€å¸ˆæ‰€æ±‡æ€»çš„èµ„æºæå…¶ä¼˜è´¨`ï¼Œè¯¾ç¨‹ä¸­ä¼šæåŠç»å…¸è®ºæ–‡å¯¹åº”çš„ä»£ç åº“ã€åŸºç¡€æ¦‚å¿µçš„ web-demo ç­‰ã€‚å› æ­¤ï¼Œæˆ‘æ‰“ç®—äºŒåˆ·ï¼Œå¹¶ä¸”å°†é‡ç‚¹é›†ä¸­åœ¨å®è·µä¸Šã€‚

è¯¾ç¨‹ç›®å½•è§ [link](#Zhou-Readme) ï¼Œæˆ‘çš„ç¬”è®°è§ [notes](./notes/README.md) ã€‚

### RLChina
åäººå¼ºåŒ–å­¦ä¹ é¡¶å°–å­¦è€…ç¤¾åŒº RLChina ä¸¾åŠçš„å…¬ç›Šæ´»åŠ¨ï¼Œè´¨é‡å¾ˆé«˜ï¼Œä¸”å°†æ³¨æ„åŠ›é›†ä¸­åœ¨äº†`å¼¥è¡¥ MARL è¿™éƒ¨åˆ†èµ„æ–™ç¼ºå¤±çš„çŸ­æ¿`ï¼Œå¯ä»¥ç†è§£ä¸ºå„ä¸ªå…ˆè¿›é¢†åŸŸçš„è®²åº§ï¼š
- é™¤å»å¼€å¤´çš„åŸºç¡€çŸ¥è¯†é“ºå«ï¼ŒåŒ…å«ï¼š
  - å°†æ¨ç†æ¨¡å‹åº”ç”¨äºæ§åˆ¶ Control as Inference ï¼›
  - æ¨¡ä»¿å­¦ä¹  Imitation Learning ï¼›
  - ç¨€ç–å¥–åŠ±ä¸‹çš„å¼ºåŒ–å­¦ä¹  Learning with Sparse Rewards ï¼›
  - åšå¼ˆè®º Game Theory Basic ï¼›
  - å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ Multi-agent Systems åŠ MARL çš„æ‰©å±•ï¼ˆå…±4èŠ‚ï¼‰ã€‚
- å¤šæ™ºèƒ½ä½“éƒ¨åˆ†ï¼Œå°†åœ¨æœ€åä¸€éƒ¨åˆ†ä»‹ç»å´­æ–°çš„æ€è·¯ï¼šä½¿ç”¨ç‰©ç†ä¸­çš„ Mean-Field ç†è®ºï¼Œå»ç ”ç©¶å¤§è§„æ¨¡æ™ºèƒ½ä½“æ§åˆ¶ã€‚

2020å¹´8æœˆä»½çš„è¯¾ç¨‹ï¼Œå¾ˆæ–°ï¼Œå½“æ—¶æ²¡æœ‰çœ‹ç›´æ’­ï¼ˆç›´æ’­ä¸èƒ½è‡ªå·±è°ƒèŠ‚è¿›åº¦ï¼‰ã€‚ä¼šåœ¨2020å¹´12æœˆä»½å‰å®Œæˆè¯¾ç¨‹ç¬”è®°ã€‚

è¯¾ç¨‹ç›®å½•è§ [link](./RLChina/notes/README.md) ï¼Œæˆ‘çš„ç¬”è®°è§ [notes](./RLChina/notes/README.md) ã€‚

# Zhou-Readme
![teaser](asset/teaser.png)
## Overview
This short RL course introduces the basic knowledge of reinforcement learning. Slides are made in English and lectures are given by [Bolei Zhou](http://bzhou.ie.cuhk.edu.hk/) in Mandarin. The course is for personal educational use only. Please open an issue if you spot some typos or errors in the slides. 

## Course Schedule
The course is scheduled as follows. There are 10 lectures in total, where the first one was premiered on 16 March 2020 and the last one was finished on 25 May 2020. Thanks for watching and may ReinForce be with you!

|            	  | Topic                                      	  | Resources |
|--------------	|----------------------------------------------	|----------	|
|  Lecture1 	| Overview (è¯¾ç¨‹æ¦‚æ‹¬ä¸RLåŸºç¡€)                                   	|[slide](lecture1.pdf), Youtube([part1](https://www.youtube.com/watch?v=IkEF4LpH5Ys), [part2](https://www.youtube.com/watch?v=Qu8CPnnwplM)), Bç«™([ä¸Šé›†](https://www.bilibili.com/video/BV1LE411G7Xj/), [ä¸‹é›†](https://www.bilibili.com/video/BV1g7411Z7SJ/))  |
|  Lecture2 	| Markov Decision Process (é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹)                    	| [slide](lecture2.pdf), Youtube([part1](https://www.youtube.com/watch?v=6yE9XiIB3hQ), [part2](https://www.youtube.com/watch?v=MIZbocCu7Sk)), Bç«™([ä¸Šé›†](https://www.bilibili.com/video/BV1g7411m7Ms/), [ä¸‹é›†](https://www.bilibili.com/video/BV1u7411m7rh/)) |
|  Lecture3 	| Model-free Prediction and Control (æ— æ¨¡å‹çš„é¢„æµ‹å’Œæ§åˆ¶)          	|  [slide](lecture3.pdf), Youtube([part1](https://www.youtube.com/watch?v=Duj1U73yHik), [part2](https://www.youtube.com/watch?v=sfkhinBjGGY)), Bç«™([ä¸Šé›†](https://www.bilibili.com/video/BV1N7411Q7aJ/), [ä¸‹é›†](https://www.bilibili.com/video/BV1N7411Q7M6/)) |
|  Lecture4 	| Value Function Approximation (ä»·å€¼å‡½æ•°è¿‘ä¼¼)               	|[slide](lecture4.pdf), Youtube([part1](https://www.youtube.com/watch?v=YdWsnB-u8PQ), [part2](https://www.youtube.com/watch?v=fGIaFlbBFxk)), Bç«™([ä¸Šé›†](https://www.bilibili.com/video/BV11V411f7bi/), [ä¸‹é›†](https://www.bilibili.com/video/BV1w54y1d7se/))  |
|  Lecture5 	| Policy Optimization: Foundation (ç­–ç•¥ä¼˜åŒ–åŸºç¡€ç¯‡)             |[slide](lecture5.pdf), Youtube([part1](https://www.youtube.com/watch?v=ProKaoyduFY), [part2](https://www.youtube.com/watch?v=MWXazkQkTlk)), Bç«™([ä¸Šé›†](https://www.bilibili.com/video/BV1fZ4y1x7mp/), [ä¸‹é›†](https://www.bilibili.com/video/BV1ia4y1x7Va/))            	|
|  Lecture6 	| Policy Optimization: State of the art (ç­–ç•¥ä¼˜åŒ–è¿›é˜¶ç¯‡)      	|[slide](lecture6.pdf), Youtube([part1](https://youtu.be/4YIdjLh-MJs), [part2](https://youtu.be/HOpiQWM0PCA)), Bç«™([ä¸Šé›†](https://www.bilibili.com/video/BV1s64y1M7AW/), [ä¸‹é›†](https://www.bilibili.com/video/BV1EK41157fD/))  |
|  Lecture7 	| Model-based RL (åŸºäºç¯å¢ƒæ¨¡å‹çš„RL)                             	|[slide](lecture7.pdf), [Youtube](https://youtu.be/2Cy8ZX16pBU), [Bç«™](https://www.bilibili.com/video/BV1hV411d7Sg/)|
|  Lecture8 	| Imitation Learning (æ¨¡ä»¿å­¦ä¹ )                         	|[slide](lecture8.pdf), [Youtube](https://youtu.be/Sqvn6RxU8qk), [Bç«™](https://www.bilibili.com/video/BV17k4y1k7Gu/)           	|
| Lecture9 	| Distributed systems for RL (åˆ†å¸ƒå¼ç³»ç»Ÿ) 	|[slide](lecture9.pdf), [Youtube](https://youtu.be/PyHGeFFfaWk), [Bç«™](https://www.bilibili.com/video/BV1bi4y147Rv/)           	|
| Lecture10 	| RL in a nutshell (è¯¾ç¨‹ç»“å±€ç¯‡)|[slide](lecture10.pdf), [Youtube](https://youtu.be/bDGmKVKAdHg), [Bç«™](https://www.bilibili.com/video/BV1si4y1s7oQ/)           	|
| Bonus 1 	| DeepMind's AlphaStar Explained (å‰–ææ˜Ÿé™…äº‰éœ¸AI) by [Zhenghao Peng](https://github.com/pengzhenghao)|[slide](lecture_alphastar.pdf), [Youtube](https://youtu.be/5qp0VNC_iOc), [Bç«™](https://www.bilibili.com/video/BV1wa4y1e74G/)           	|
